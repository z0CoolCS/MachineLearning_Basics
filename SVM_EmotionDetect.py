# -*- coding: utf-8 -*-
"""SVM_Project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rbH31ZXDwA5FB5rAtHB0zc0B3hFTcnfo

Data comes from 
[here](https://drive.google.com/file/d/1-g5ifF2Vev47XkGX2QZ-Ix57Ku4aPkXR/view?usp=sharing)
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg 
import pickle
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import KFold
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
import seaborn as sn

"""## *Read data from pickle files*"""

path_X = '/content/drive/MyDrive/Colab Notebooks/UTEC - IA/data/face_dataset/X.pickle'
path_y = '/content/drive/MyDrive/Colab Notebooks/UTEC - IA/data/face_dataset/y.pickle'
pickle_Xin = open(path_X, "rb")
pickle_yin = open(path_y, "rb")
X = pickle.load(pickle_Xin)
y = pickle.load(pickle_yin)

"""## *Build training and test data sets with the entire Data*"""

np.random.seed(100)
X_train, X_test, y_train, y_test = train_test_split(X[0], y[0], test_size = 0.20)
for i in range(1, len(X)):
  X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(X[i], y[i], test_size = 0.20)
  X_train = np.concatenate([X_train, X_train_i])
  y_train = np.concatenate([y_train, y_train_i])
  X_test = np.concatenate([X_test, X_test_i])
  y_test = np.concatenate([y_test, y_test_i])

"""## *KFold Cross Validation*

### *Linear Model*
"""

accuracy_linear = []
# evaluation of linear model between different k values
for i in range(2, 20):
  kf = KFold(n_splits = i)
  local_accuracy = 0
  for train_index, test_index in kf.split(X_train):
    # getting training data from training set for evaluate linear model
    X_train_train = X_train[train_index]
    y_train_train = y_train[train_index]
    # getting test data from training set for evaluate linear model
    X_train_test = X_train[test_index]
    y_train_test = y_train[test_index]
    # creating linear model
    svc_model = SVC(kernel='linear')
    # fitting linear model
    svc_model.fit(X_train_train, y_train_train)
    # predicting with test data
    y_pred = svc_model.predict(X_train_test)
    
    # getting accuracy for k values
    cm = confusion_matrix(y_train_test,y_pred)
    local_accuracy_i = sum(np.diag(cm)) / y_train_test.shape[0]
    local_accuracy += local_accuracy_i
  local_accuracy /= i
  print(f'K values: {i}, local accuracy: {local_accuracy}')
  accuracy_linear.append(local_accuracy)
print(f'Average accuracy value for linear model :{sum(accuracy_linear) / len(accuracy_linear)}')

ind_max_lin = accuracy_linear.index(max(accuracy_linear)) + 2
plt.plot(np.arange(2, 20), accuracy_linear, 'o-')
plt.xlabel("K value")
plt.ylabel("Accuracy")
plt.vlines(ind_max_lin, 0, max(accuracy_linear), linestyles='dashed', colors='red', label="Highest Accuracy")
plt.text(ind_max_lin + .2, max(accuracy_linear), round(max(accuracy_linear), 3))
plt.text(ind_max_lin + .2, 0, 'k='+str(ind_max_lin))
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Accuracy by k Value in Linear Model")
plt.show()

"""### *Polinomial Model*"""

accuracy_polynomial = []
# evaluation of polynomial model between different k values
for grade in range(2, 10):
  local_accuracy_grade = 0
  print(f'Polynomial grade: {grade}')
  for i in range(2, 20):
    kf = KFold(n_splits = i)
    local_accuracy = 0
    for train_index, test_index in kf.split(X_train):
      # getting training data from training set for evaluate polynomial model
      X_train_train = X_train[train_index]
      y_train_train = y_train[train_index]
      # getting test data from training set for evaluate polynomial model
      X_train_test = X_train[test_index]
      y_train_test = y_train[test_index]
      # creating polynomial model
      svc_model = SVC(kernel='poly', degree = grade)
      # fitting polynomial model
      svc_model.fit(X_train_train, y_train_train)
      # predicting with test data
      y_pred = svc_model.predict(X_train_test)
      
      # getting accuracy for k values
      cm = confusion_matrix(y_train_test,y_pred)
      local_accuracy_k = sum(np.diag(cm)) / y_train_test.shape[0]
      local_accuracy += local_accuracy_k
    local_accuracy /= i
    print(f'K values: {i}, local accuracy: {local_accuracy}')
    local_accuracy_grade += local_accuracy
  local_accuracy_grade /= 18
  accuracy_polynomial.append(local_accuracy_grade)
print(f'Average accuracy value for Polynomial model :{sum(accuracy_polynomial) / len(accuracy_polynomial)}')

ind_max_poly = accuracy_polynomial.index(max(accuracy_polynomial)) + 2
plt.plot(np.arange(2, 10), accuracy_polynomial, 'o-')
plt.xlabel("Polynomial Grade")
plt.ylabel("Accuracy")
plt.vlines(ind_max_poly, 0, max(accuracy_polynomial), linestyles='dashed', colors='red', label="Highest Accuracy")
plt.text(ind_max_poly + .2, max(accuracy_polynomial), round(max(accuracy_polynomial), 3))
plt.text(ind_max_poly + .2, 0, 'k='+str(ind_max_poly))
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Accuracy by k Value in Polynomial Model")
plt.show()

"""### *RBF Model*"""

accuracy_rbf = []
# evaluation of rbf model between different k values
for i in range(2, 20):
  kf = KFold(n_splits = i)
  local_accuracy = 0
  for train_index, test_index in kf.split(X_train):
    # getting training data from training set for evaluate rbf model
    X_train_train = X_train[train_index]
    y_train_train = y_train[train_index]
    # getting test data from training set for evaluate rbf model
    X_train_test = X_train[test_index]
    y_train_test = y_train[test_index]
    # creating rbf model
    svc_model = SVC(kernel='rbf')
    # fitting rbf model
    svc_model.fit(X_train_train, y_train_train)
    # predicting with test data
    y_pred = svc_model.predict(X_train_test)
    
    # getting accuracy for k values
    cm = confusion_matrix(y_train_test,y_pred)
    local_accuracy_i = sum(np.diag(cm)) / y_train_test.shape[0]
    local_accuracy += local_accuracy_i
  local_accuracy /= i
  print(f'K values: {i}, local accuracy: {local_accuracy}')
  accuracy_rbf.append(local_accuracy)
print(f'Average accuracy value for rbf model :{sum(accuracy_rbf) / len(accuracy_rbf)}')

ind_max_rbf = accuracy_rbf.index(max(accuracy_rbf)) + 2
plt.plot(np.arange(2, 20, 1), accuracy_rbf, 'o-')
plt.xlabel("K value")
plt.ylabel("Accuracy")
plt.vlines(ind_max_rbf, 0, max(accuracy_rbf), linestyles='dashed', colors='red', label="Highest Accuracy")
plt.text(ind_max_rbf + .2, max(accuracy_rbf), round(max(accuracy_rbf), 3))
plt.text(ind_max_rbf + .2, 0, 'k='+str(ind_max_rbf))
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Accuracy by k Value in RBF Model")
plt.show()

"""### *Sigmoid Model*"""

accuracy_sigmoid = []
# evaluation of sigmoid model between different k values
for i in range(2, 20):
  kf = KFold(n_splits = i)
  local_accuracy = 0
  for train_index, test_index in kf.split(X_train):
    # getting training data from training set for evaluate sigmoid model
    X_train_train = X_train[train_index]
    y_train_train = y_train[train_index]
    # getting test data from training set for evaluate sigmoid model
    X_train_test = X_train[test_index]
    y_train_test = y_train[test_index]
    # creating sigmoid model
    svc_model = SVC(kernel='sigmoid')
    # fitting sigmoid model
    svc_model.fit(X_train_train, y_train_train)
    # predicting with test data
    y_pred = svc_model.predict(X_train_test)
    
    # getting accuracy for k values
    cm = confusion_matrix(y_train_test,y_pred)
    local_accuracy_i = sum(np.diag(cm)) / y_train_test.shape[0]
    local_accuracy += local_accuracy_i
  local_accuracy /= i
  print(f'K values: {i}, local accuracy: {local_accuracy}')
  accuracy_sigmoid.append(local_accuracy)
#accuracy_sigmoid = np.array(accuracy_sigmoid)
print(f'Average accuracy value for sigmoid model :{sum(accuracy_sigmoid) / len(accuracy_sigmoid)}')

ind_max_sig = accuracy_sigmoid.index(max(accuracy_sigmoid)) + 2
plt.plot(np.arange(2, 20, 1), accuracy_sigmoid, 'o-')
plt.xlabel("K value")
plt.vlines(ind_max_sig, 0, max(accuracy_sigmoid), linestyles='dashed', colors='red', label="Highest Accuracy")
plt.text(ind_max_sig + .2, max(accuracy_sigmoid), round(max(accuracy_sigmoid), 3))
plt.text(ind_max_sig + .2, 0, 'k='+str(ind_max_sig))
plt.ylabel("Accuracy")
plt.title("Accuracy by k Value in Sigmoid Model")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.show()

"""## *Bootstrap Validation*

### *Linear Model*
"""

np.random.seed(100)
accuracy_lm_bootstrap = []
t = 10
n_samples_train = int(X_train.shape[0] * 0.8)
for i in range(t):
  index = np.arange(0, X_train.shape[0])
  train_index = resample(index, n_samples=n_samples_train, replace=True, random_state=i)
  test_index = np.array(list(set(index) - set(np.unique(train_index))))
  X_train_train = X_train[train_index]
  y_train_train = y_train[train_index]
  # getting test data from training set for evaluate linear model
  X_train_test = X_train[test_index]
  y_train_test = y_train[test_index]
  # creating linear model
  svc_model = SVC(kernel='linear')
  # fitting linear model
  svc_model.fit(X_train_train, y_train_train)
  # predicting with test data
  y_pred = svc_model.predict(X_train_test)
    
  # getting accuracy for k values
  cm = confusion_matrix(y_train_test,y_pred)
  local_accuracy_i = sum(np.diag(cm)) / y_train_test.shape[0]
  accuracy_lm_bootstrap.append(local_accuracy_i) 
  print(f'Random state:: {i}, local accuracy: {local_accuracy_i}')
print(f'Average accuracy value for linear model :{sum(accuracy_lm_bootstrap) / len(accuracy_lm_bootstrap)}')

ind_max_lin_boot = accuracy_lm_bootstrap.index(max(accuracy_lm_bootstrap))
plt.plot(np.arange(0, 10), accuracy_lm_bootstrap, 'o-')
plt.xlabel("Iteration")
plt.ylabel("Accuracy")
plt.vlines(ind_max_lin_boot, 0, max(accuracy_lm_bootstrap), linestyles='dashed', colors='red', label="Highest Accuracy")
plt.text(ind_max_lin_boot + .2, max(accuracy_lm_bootstrap), round(max(accuracy_lm_bootstrap), 3))
plt.text(ind_max_lin_boot + .2, 0.81, 't='+str(ind_max_lin_boot))
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Accuracy in Linear Model with Bootstrap")
plt.ylim(.8,1)
plt.show()

"""### *RBF Model*"""

np.random.seed(100)
accuracy_rbf_bootstrap = []
t = 10
n_samples_train = int(X_train.shape[0] * 0.8)
for i in range(t):
  index = np.arange(0, X_train.shape[0])
  train_index = resample(index, n_samples=n_samples_train, replace=True, random_state=i)
  test_index = np.array(list(set(index) - set(np.unique(train_index))))
  X_train_train = X_train[train_index]
  y_train_train = y_train[train_index]
  # getting test data from training set for evaluate rbf model
  X_train_test = X_train[test_index]
  y_train_test = y_train[test_index]
  # creating rbf model
  svc_model = SVC(kernel='rbf')
  # fitting rbf model
  svc_model.fit(X_train_train, y_train_train)
  # predicting with test data
  y_pred = svc_model.predict(X_train_test)
    
  # getting accuracy for k values
  cm = confusion_matrix(y_train_test,y_pred)
  local_accuracy_i = sum(np.diag(cm)) / y_train_test.shape[0]
  accuracy_rbf_bootstrap.append(local_accuracy_i) 
  print(f'Random state:: {i}, local accuracy: {local_accuracy_i}')
print(f'Average accuracy value for rbf model :{sum(accuracy_rbf_bootstrap) / len(accuracy_rbf_bootstrap)}')

ind_max_rbf_boot = accuracy_rbf_bootstrap.index(max(accuracy_rbf_bootstrap))
plt.plot(np.arange(0, 10), accuracy_rbf_bootstrap, 'o-')
plt.xlabel("Iteration")
plt.ylabel("Accuracy")
plt.vlines(ind_max_rbf_boot, 0, max(accuracy_rbf_bootstrap), linestyles='dashed', colors='red', label="Highest Accuracy")
plt.text(ind_max_rbf_boot + .2, max(accuracy_rbf_bootstrap), round(max(accuracy_rbf_bootstrap), 3))
plt.text(ind_max_rbf_boot + .2, 0.71, 't='+str(ind_max_rbf_boot))
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Accuracy Value in RBF Model with Bootstrap")
plt.ylim(.7,1)
plt.show()

"""## *Model SVM*

### *Create and Fitting the model*
"""

svc_model = SVC(kernel='linear')
svc_model.fit(X_train, y_train)

"""### *Predict with test data*"""

y_pred = svc_model.predict(X_test)

cm = confusion_matrix(y_test,y_pred)
cr = classification_report(y_test,y_pred)
print(f'Accuracy: {np.round(sum(np.diag(cm)/y_pred.shape[0]), 3)}')
print(cm)
print(cr)

plt.figure(figsize = (10,7))
sn.heatmap(cm / y_test.shape[0], annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.title("Relative Confusion Matrix")
plt.show()

"""## PCA"""

from sklearn.decomposition import PCA
features_n = [50, 100, 200, 300, 400]
explained_p = []
accuracy_pca = []
for size_n in features_n:
  p = PCA(n_components=size_n, whiten=True).fit(X_train)
  X = p.transform(X_train)
  print(f'Explained value: {sum(p.explained_variance_ratio_)}')
  explained_p.append(sum(p.explained_variance_ratio_))
  svc_model = SVC(kernel='linear')
  svc_model.fit(X, y_train)
  x_p = p.transform(X_test)
  y_pred = svc_model.predict(x_p)
  cm = confusion_matrix(y_test,y_pred)
  print(f'Size:{size_n}, Accuracy:{sum(np.diag(cm))/y_test.shape[0]}')
  accuracy_pca.append(sum(np.diag(cm))/y_test.shape[0])

plt.plot(features_n, accuracy_pca, 'o-')
ind_max_ac_pca = features_n[accuracy_pca.index(max(accuracy_pca))]
plt.plot(features_n, accuracy_pca, 'o-')
plt.xlabel("Size of Training Set")
plt.ylabel("Accuracy")
plt.vlines(ind_max_ac_pca, 0, max(accuracy_pca), linestyles='dashed', colors='red', label="Highest Accuracy")
plt.text(ind_max_ac_pca + 5, max(accuracy_pca), round(max(accuracy_pca), 3))
plt.text(ind_max_ac_pca + 5, 0.953, 'n='+str(ind_max_ac_pca))
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Accuracy by Size of Training Set Value")
plt.ylim(.95,1)
plt.show()

plt.plot(features_n, explained_p, 'o-')
ind_max_ex_pca = features_n[explained_p.index(max(explained_p))]
plt.plot(features_n, explained_p, 'o-')
plt.xlabel("Size of Training Set")
plt.ylabel("Accuracy")
plt.vlines(ind_max_ex_pca, 0, max(explained_p), linestyles='dashed', colors='red', label="Highest Explained Value")
plt.text(ind_max_ex_pca + 5, max(explained_p), round(max(explained_p), 3))
plt.text(ind_max_ex_pca + 5, 0.953, 'n='+str(ind_max_ex_pca))
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
plt.title("Explained by Size of Training Set Value")
plt.ylim(.935,1)
plt.show()

from sklearn.decomposition import PCA
np.random.seed(100)
p = PCA(n_components=100, whiten=True).fit(X_train)
X = p.transform(X_train)

sum(p.explained_variance_ratio_)

svc_model = SVC(kernel='linear')
svc_model.fit(X, y_train)

xtest_100 = p.transform(X_test)
y_pred_100 = svc_model.predict(xtest_100)

cm_100 = confusion_matrix(y_test,y_pred_100)
cr_100 = classification_report(y_test,y_pred_100)
print(cm_100)
print(cr_100)

np.round(sum(np.diag(cm_100))/y_test.shape[0], 3)

plt.figure(figsize = (10,7))
sn.heatmap(cm_100 / y_test.shape[0], annot=True)
plt.xlabel('Predicted')
plt.ylabel('Truth') 
plt.title("Relative Confusion Matrix")
plt.show()